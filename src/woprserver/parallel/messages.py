"""
Message schema for worker/dispatcher RPC — in‑depth docs
=======================================================

This module defines the **wire format** (Pydantic models) exchanged between the
parent process (dispatcher) and worker processes. Messages fall into three
buckets:

1. **Request/Response** — call a model method and return either a value or an
   error.
2. **Control plane (Model updates)** — load/unload models inside workers.
3. **Streaming** — both directions:
   - *worker → client*: chunks and terminal end/exception.
   - *client → worker*: input chunks for streaming parameters, scoped by a
     request id and a per‑parameter ``channel_id``.

Design goals
------------
* Keep messages **immutable and explicit**; forbid unknown fields (``extra='forbid'``).
* Avoid shared mutable defaults (use ``default_factory`` for lists/dicts).
* **Lazy materialization** of ``ModelSettings``: we carry a JSON string across
  processes to avoid cross‑version Pydantic pitfalls and only parse on demand.
* Allow arbitrary exception types in responses while keeping Pydantic strict
  elsewhere.

Compatibility
-------------
The ``model_settings`` (de)serialization works with both **Pydantic v1** and
**Pydantic v2** ``ModelSettings`` implementations. The code first tries the v2
API (``model_validate_json``), then v1 (``parse_raw``), and finally a generic
``model_validate`` from a dict.
"""

import json
from asyncio import CancelledError
from enum import IntEnum
from typing import Any

from mlserver.settings import ModelSettings
from mlserver.utils import generate_uuid
from pydantic import BaseModel, ConfigDict, Field, model_validator

# ---- Enums -----------------------------------------------------------------

class ModelUpdateType(IntEnum):
    """Types of control‑plane updates that can be applied to workers."""
    Load = 1
    Unload = 2


# ---- Base message ----------------------------------------------------------

class Message(BaseModel):
    """
    Base message carrying a unique ID used to correlate requests and responses.

    The ``id`` is a UUID string generated by ``mlserver.utils.generate_uuid``.
    All concrete message types inherit from this base to ensure consistent
    correlation across the system.
    """
    model_config = ConfigDict(
        protected_namespaces=(),      # allow attributes like "model_config" on subclasses
        extra="forbid",              # reject unexpected fields for safety
    )

    id: str = Field(default_factory=generate_uuid)


# ---- Request / Response ----------------------------------------------------

class ModelRequestMessage(Message):
    """
    A request to call a method on a model inside a worker.

    Fields
    ------
    * ``model_name`` / ``model_version`` — identify the target model instance.
    * ``method_name`` — the attribute to call on the model (e.g., ``predict``).
    * ``method_args`` / ``method_kwargs`` — positional/keyword arguments.
      These may contain ``InputChannelRef`` placeholders for streaming params.
    """
    model_name: str
    model_version: str | None = None
    method_name: str
    method_args: list[Any] = Field(default_factory=list)           # no shared mutable defaults
    method_kwargs: dict[str, Any] = Field(default_factory=dict)


class ModelResponseMessage(Message):
    """
    Response to a request. Exactly one of ``return_value`` or ``exception``
    should be set. ``arbitrary_types_allowed`` is enabled so exceptions can be
    carried without coercion.
    """
    model_config = ConfigDict(arbitrary_types_allowed=True, extra="forbid")

    return_value: Any | None = None
    exception: Exception | CancelledError | None = None

    def ok(self) -> bool:
        """True if no exception was returned (happy path)."""
        return self.exception is None

    def raise_for_exception(self) -> None:
        """Raise the contained exception if present (helper for callers)."""
        if self.exception is not None:
            raise self.exception


# ---- Model updates ---------------------------------------------------------

class ModelUpdateMessage(Message):
    """
    Control‑plane message to (un)load a model in a worker.

    Accepts either of the following at construction time:
    - ``serialised_model_settings`` — a JSON string representation of the
      ``ModelSettings`` instance (preferred for process boundaries), or
    - ``model_settings`` — a concrete ``ModelSettings`` object which we will
      serialize before validation completes.
    """
    model_config = ConfigDict(arbitrary_types_allowed=True, extra="forbid")

    update_type: ModelUpdateType
    serialised_model_settings: str

    # Accept `model_settings` as input and turn it into JSON before validation completes.
    @model_validator(mode="before")
    @classmethod
    def _serialize_model_settings(cls, data: Any):
        """Normalize input by ensuring we always store JSON in ``serialised_model_settings``.

        This hook runs before full model validation. If the caller provided a
        ``model_settings`` object (or dict‑like), we convert it into a compact
        JSON string and stash it under ``serialised_model_settings``.
        """
        if not isinstance(data, dict):
            return data

        # If the caller passed an actual ModelSettings instance, serialize it.
        if "model_settings" in data and "serialised_model_settings" not in data:
            ms = data.pop("model_settings")
            if isinstance(ms, ModelSettings):
                as_dict = ms.model_dump(by_alias=True)
                # Preserve private _source if present (useful for provenance)
                if getattr(ms, "_source", None):
                    as_dict["_source"] = ms._source
                data["serialised_model_settings"] = json.dumps(
                    as_dict, ensure_ascii=False, separators=(",", ":")
                )
            else:
                # If it's already a dict-like structure, serialize that too.
                data["serialised_model_settings"] = json.dumps(
                    ms, ensure_ascii=False, separators=(",", ":")
                )
        return data

    @property
    def model_settings(self) -> ModelSettings:
        """
        Lazily materialize ``ModelSettings`` from its serialized JSON.

        Tries Pydantic v2 (``model_validate_json``) first, then v1
        (``parse_raw``). As a last resort, parses JSON to a dict and calls a
        generic ``model_validate``.
        """
        # Pydantic v2
        parse_v2 = getattr(ModelSettings, "model_validate_json", None)
        if callable(parse_v2):
            return parse_v2(self.serialised_model_settings)  # type: ignore[attr-defined]

        # Pydantic v1 fallback
        parse_v1 = getattr(ModelSettings, "parse_raw", None)
        if callable(parse_v1):
            return parse_v1(self.serialised_model_settings)  # type: ignore[attr-defined]

        # As a last resort, try constructing from dict
        return ModelSettings.model_validate(json.loads(self.serialised_model_settings))  # type: ignore[attr-defined]

    @classmethod
    def from_model_settings(cls, update_type: ModelUpdateType, model_settings: ModelSettings) -> "ModelUpdateMessage":
        """Convenience constructor for callers who have a concrete settings object."""
        return cls(update_type=update_type, model_settings=model_settings)


# ---- Streaming (outbound: worker -> client) --------------------------------

class ModelStreamChunkMessage(Message):
    """
    One chunk of a streaming response for the request with the same ``id``.

    The ``chunk`` field is intentionally ``Any`` to accommodate text tokens,
    JSON fragments, binary blobs, etc., depending on the model/method.
    """
    model_config = ConfigDict(arbitrary_types_allowed=True, extra="forbid")

    chunk: Any


class ModelStreamEndMessage(Message):
    """
    Marks the end of a streaming response for the request with the same ``id``.

    If ``exception`` is set, the stream ended due to an error; clients should
    raise or handle it appropriately.
    """
    model_config = ConfigDict(arbitrary_types_allowed=True, extra="forbid")

    exception: Exception | CancelledError | None = None


# ---- Streaming (inbound: client -> worker) ---------------------------------

class InputChannelRef(BaseModel):
    """
    Placeholder in args/kwargs for an inbound async stream.

    * ``id`` is the **request id**.
    * ``channel_id`` is unique **per parameter** on that request. An empty
      string represents a *legacy* single‑channel mode.
    """
    model_config = ConfigDict(extra="forbid")
    id: str
    channel_id: str = ""    # unique per stream; empty means legacy single-channel


class ModelStreamInputChunk(Message):
    """
    One inbound input item for the request with the same ``id``.

    The worker routes chunks to the correct model parameter using ``channel_id``.
    """
    model_config = ConfigDict(arbitrary_types_allowed=True, extra="forbid")
    item: Any
    channel_id: str = ""    # empty = legacy


class ModelStreamInputEnd(Message):
    """
    Marks the end of an inbound input stream for the given channel.

    The absence of further ``ModelStreamInputChunk`` messages for the same
    (``id``, ``channel_id``) pair implies completion on that channel only; other
    channels for the same request may continue.
    """
    model_config = ConfigDict(extra="forbid")
    channel_id: str = ""    # empty = legacy
